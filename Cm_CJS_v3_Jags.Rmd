---
title: "Capture recapture analyses for Agnese Mancini"
output: html_notebook
---

October 2020.

This document describes data analysis of Agnese Mancini's data of green turtle capture recapture events. IN this version, we use community (sampling site) specific data for estimating survival/capture probability, and derived abundance using CJS models. 


Initialize the workspace
```{r}
rm(list=ls())
library(jagsUI)
library(tidyverse)
library(lubridate)
library(reshape)
library(bayesplot)
library(ggridges)
library(loo)

# library(RMark)
# library(R2ucare)

source("Mancini_functions.R")
save.fig <- F

MCMC.params <- list(n.samples = 50000,
                    n.burnin = 30000,
                    n.thin = 5,
                    n.chains = 5)

models <- list(list(ID = 1, name = "Model_CJS_Phidot_pdot.txt"),
               list(ID = 2, name = "Model_CJS_Phidot_pt.txt"),
               list(ID = 3, name = "Model_CJS_Phidot_pEffort.txt"),
               list(ID = 4, name = "Model_CJS_PhiAgeClass_pdot.txt"),
               list(ID = 5, name = "Model_CJS_PhiAgeClass_pt.txt"),
               list(ID = 6, name = "Model_CJS_PhiAgeClass_pEffort.txt"),
               list(ID = 7, name = "Model_CJS_PhiMinCCL_pdot.txt"),
               list(ID = 8, name = "Model_CJS_PhiMinCCL_pt.txt"),
               list(ID = 9, name = "Model_CJS_PhiMinCCL_pEffort.txt"),
               list(ID = 10, name = "Model_CJS_PhiTSM_pdot.txt"),
               list(ID = 11, name = "Model_CJS_PhiTSM_pt.txt"),
               list(ID = 12, name = "Model_CJS_PhiTSM_pEffort.txt"))


```

Bring in the data file and get ready for CJS

```{r warning=F}
#dat.1 <- get.data("data/GTC_20190725_Tomo_v2.csv")

dat.1.Cm <- get.data.Cm("data/GTC_Cm Data_updated_2020-04-28_TE_v2.csv")

dat.1.Cm %>% 
  select(ID, CCL) %>% 
  na.omit() %>%
  group_by(ID) %>%
  summarise(min_CCL = min(CCL, na.rm = T)) %>% #-> tmp
  filter(!is.infinite(min_CCL)) -> data.CCL

# Group by community and create CJS data for each community
community.names <- levels(as.factor(dat.1.Cm$community))

# some communities don't have enough recaptures to do CMR modeling
c <- 0
k <- 2
k1 <- k2 <- 1

p.recap <- vector(mode = "numeric")
community.names.used <- vector(mode = "character")

for (k in 1:length(community.names)){
  
  dat.1.Cm.community <- filter(dat.1.Cm, community == community.names[k])
  CJS.data <- dat2CJS(dat.1.Cm.community, save.file = FALSE)
  n.GT2.cap <- length(which(rowSums(CJS.data$data) > 1))
  p.recap[k] <- n.GT2.cap/nrow(CJS.data$data)
  
  if (p.recap[k] > 0.05){
    community.names.used[c + 1] <- community.names[k]
    CJS.data$data %>% rownames_to_column(var = "ID") -> CH.1 #data.CJS
    
    cap.dates <- paste0(colnames(CJS.data$data), "-01")
    delta.dates <- signif(as.numeric(as.Date(cap.dates[2:length(cap.dates)]) -
                                       as.Date(cap.dates[1:(length(cap.dates)-1)]))/365, 1)
    # 
    
    data.CCL  %>% left_join(CH.1, by = "ID") %>%
      select(min_CCL) -> cov.CCL
    
    # capture history
    CH <- as.matrix(CJS.data$data)
    
    nInd <- nrow(CJS.data$data)
    
    ns <- colSums(CJS.data$data)
    
    # find the first capture date
    get.first <- function(x) min(which(x != 0))
    first.cap <- apply(CH, 1, get.first)
    
    m <- matrix(data = 2, nrow = nrow(CH), ncol = ncol(CH))
    for (k2 in 1:nrow(m)){
      m[k2, first.cap[k2]] <- 1
    }
    
    jags.data <- list(y = CH, 
                      f = first.cap, 
                      nind = nInd, 
                      n.occasions = dim(CH)[2],
                      n = ns, 
                      T = ncol(CJS.data$data),
                      dt = c(0, delta.dates),
                      mean.K = 2000,
                      m = m,
                      x = as.vector(t(cov.CCL)))
    
    ## parameters to monitor - when this is changed, make sure to change
    ## summary statistics index at the end of this script. 
    parameters <- c("beta", "gamma", "p", "N", "prop.trans", 
                    "mu_N", "sigma_N", "r", "K", "sigma_logitP",
                    "mu", "mu1", "mu2", "mu.p", "beta.p",
                    "deviance", "loglik")
    
    jags.input <- list(raw.data = dat.1.Cm.community,
                       CJS.data = CJS.data,
                       CH.1 = CH.1,
                       jags.data = jags.data,
                       parameters.to.save = parameters,
                       run.date = Sys.Date())
    
    if (!file.exists(paste0("RData/CJS_Cm_jags_input_", community.names[k], ".rds")))
      saveRDS(jags.input, 
              file = paste0("RData/CJS_Cm_jags_input_", community.names[k], ".rds"))        
    
    #loo.out <- list()
    for (k1 in 1:length(models)){
      # models need to change according to the output from Mark, or do we do 
      # a similar model selection process using Pareto K?
      if (!file.exists(paste0("RData/CJS_Cm_jags_M",
                              models[[k1]]$ID, "_", 
                              community.names[k], ".rds"))){
        
        MCMC.params$model.file <- paste0("models/", models[[k1]]$name)
        
        jm <- jags(data = jags.data,
                   parameters.to.save= parameters,
                   model.file = MCMC.params$model.file,
                   n.chains = MCMC.params$n.chains,
                   n.burnin = MCMC.params$n.burnin,
                   n.thin = MCMC.params$n.thin,
                   n.iter = MCMC.params$n.samples,
                   DIC = T, 
                   parallel=T)
        
        saveRDS(jm, 
                file = paste0("RData/CJS_Cm_jags_M",
                              models[[k1]]$ID, "_", 
                              community.names[k], ".rds"))
      } else {
        
        jm <- readRDS(file = paste0("RData/CJS_Cm_jags_M",
                                    models[[k1]]$ID, "_", 
                                    community.names[k], ".rds"))
      }  
      
      # loo.out[[k1]] <- compute.LOOIC(loglik = jm$sims.list$loglik, 
      #                                MCMC.params = MCMC.params, 
      #                                data.vector = as.vector(jags.data$y))
      rm(list = c("jm"))
      
      
    }
    
    #saveRDS(loo.out, file = paste0("RData/CJS_Cm_jags_", community.names[k], "_loo.rds"))
        
    c <- c + 1
  } else {
    print(paste("Commuinity", community.names[k], 
                "did not have sufficient recapture probability (p < 0.05)."))
    community.names.used[[c+1]] <- community.names[k]
    c <- c + 1
    
  }
  
}
  


```


Goodness-of-fit using LOOIC

BKS
```{r}
loo.out <- readRDS(file = "RData/CJS_Cm_jags_BKS_loo.rds")

pareto.looic <- pareto.looic.fcn(loo.out, models)

options(scipen = 999)

models.abb <- lapply(models, FUN = function(x) x$name) %>%
  lapply(FUN = function(x) strsplit(x, "Model_CJS_")) %>%
  lapply(FUN = unlist) %>%
  lapply(FUN = function(x) x[2]) %>%
  lapply(FUN = function(x) strsplit(x, ".txt")) %>% 
  lapply(FUN = unlist) %>% unlist()

looic.table <- data.frame(model = models.abb,
                          looic = pareto.looic$looic,
                          weights = as.vector(pareto.looic$model.weights)) %>% 
  arrange(by = desc(weights)) %>%
  mutate(delta.looic = looic - min(looic)) %>%
  mutate_if(is.numeric, round, digits = 4)

best.model <- pareto.looic$good.models[which(looic == min(looic))]
pareto.k.best <- pareto.looic$good.models.pareto.k[[which(looic == min(looic))]]

```




BMA

GNO

IES

LSI

MUL

PAO

PLM


